{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17758,"status":"ok","timestamp":1657806509249,"user":{"displayName":"Darshan Adiga Haniya Narayana","userId":"13149745487125032133"},"user_tz":-60},"id":"k-5mVwtBkQ_9","outputId":"f2e499a1-682c-48a9-bed3-7c4b0554f1bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Dissertation/experiments/idiom_principle_on_magpie_corpus\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Dissertation/experiments/idiom_principle_on_magpie_corpus/"],"id":"k-5mVwtBkQ_9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15661,"status":"ok","timestamp":1657806524901,"user":{"displayName":"Darshan Adiga Haniya Narayana","userId":"13149745487125032133"},"user_tz":-60},"id":"FMirIspRwePf","outputId":"0186a886-d32b-4d44-c2e0-7c7abbf42601"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.7.0\n","  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 5.3 MB/s \n","\u001b[?25hCollecting datasets==1.6.1\n","  Downloading datasets-1.6.1-py3-none-any.whl (220 kB)\n","\u001b[K     |████████████████████████████████| 220 kB 57.6 MB/s \n","\u001b[?25hCollecting tqdm==4.49.0\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 6.9 MB/s \n","\u001b[?25hCollecting nltk==3.6.2\n","  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 57.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 62.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (4.12.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (1.21.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0->-r ./requirements.txt (line 1)) (3.13)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 60.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.1->-r ./requirements.txt (line 2)) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.1->-r ./requirements.txt (line 2)) (0.3.5.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.1->-r ./requirements.txt (line 2)) (0.70.13)\n","Collecting fsspec\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 47.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.1->-r ./requirements.txt (line 2)) (1.3.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.2->-r ./requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.2->-r ./requirements.txt (line 4)) (1.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0->-r ./requirements.txt (line 1)) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0->-r ./requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0->-r ./requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0->-r ./requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0->-r ./requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.7.0->-r ./requirements.txt (line 1)) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0->-r ./requirements.txt (line 1)) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.1->-r ./requirements.txt (line 2)) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.1->-r ./requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.6.1->-r ./requirements.txt (line 2)) (1.15.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=5ce425b2317be768e8b06afcb7b7a09b2335d9282e0053981ba0e4d4ba851d4d\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tqdm, xxhash, tokenizers, sacremoses, huggingface-hub, fsspec, transformers, nltk, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.0\n","    Uninstalling tqdm-4.64.0:\n","      Successfully uninstalled tqdm-4.64.0\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed datasets-1.6.1 fsspec-2022.5.0 huggingface-hub-0.0.8 nltk-3.6.2 sacremoses-0.0.53 tokenizers-0.10.3 tqdm-4.49.0 transformers-4.7.0 xxhash-3.0.0\n"]}],"source":["!pip install -r ./requirements.txt"],"id":"FMirIspRwePf"},{"cell_type":"markdown","metadata":{"id":"KCZSTnEIwzeW"},"source":["# Experiment: Exp0"],"id":"KCZSTnEIwzeW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAttiuDPwnCc"},"outputs":[],"source":["import pandas as pd\n","pd.options.display.max_colwidth=500\n","\n","import os\n","import sys"],"id":"GAttiuDPwnCc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fENgdXWYx6cA"},"outputs":[],"source":["from exp_helpers import run_glue_f1_macro"],"id":"fENgdXWYx6cA"},{"cell_type":"markdown","metadata":{"id":"Uo3wGcP75Zaa"},"source":["## Experiment Setup"],"id":"Uo3wGcP75Zaa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3ff8t4P3Qop"},"outputs":[],"source":["exp_name = 'exp0'\n","exp_model = 'bert-base-cased'\n","exp_seed = 26"],"id":"E3ff8t4P3Qop"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f1f49ed"},"outputs":[],"source":["base_dir = 'data/magpie/'\n","# NOTE: This notebook should ideally modify only the contents of this exp_dir.\n","exp_dir = 'experiments/' + exp_name + '/'\n","data_file = base_dir + 'processed_MAGPIE_filtered_split_typebased.csv'\n","\n","tmp_dir = exp_dir + 'tmp/'\n","model_checkpoint_dir = exp_dir + 'models/'"],"id":"5f1f49ed"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RocSG08XX1HU"},"outputs":[],"source":["# %rm -rf $exp_dir"],"id":"RocSG08XX1HU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh4PU__T3J4K"},"outputs":[],"source":["if os.path.isdir(exp_dir):\n","    print(f'ERROR! The experiment directory {exp_dir} already exists!')\n","    print(\"Run '%rm -rf $exp_dir\")\n","    assert not os.path.isdir(exp_dir)\n","\n","if not os.path.isdir(tmp_dir):\n","    os.makedirs(tmp_dir)\n","\n","if not os.path.isdir(model_checkpoint_dir):\n","    os.makedirs(model_checkpoint_dir)"],"id":"Mh4PU__T3J4K"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":606},"executionInfo":{"elapsed":1569,"status":"ok","timestamp":1657806539041,"user":{"displayName":"Darshan Adiga Haniya Narayana","userId":"13149745487125032133"},"user_tz":-60},"id":"fe3ba613","outputId":"9e586b93-467c-445e-c47e-ebd0b0adcd12","scrolled":true},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-92a2a18b-c1e9-43ac-9789-10f5062345f8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_0</th>\n","      <th>idiom</th>\n","      <th>confidence</th>\n","      <th>label</th>\n","      <th>split</th>\n","      <th>variant_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?</td>\n","      <td>off the beaten track</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I 'd keep him well in the running .</td>\n","      <td>in the running</td>\n","      <td>0.770109</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>He gives me the creeps , so I looked round , hmm hmm .</td>\n","      <td>give someone the creeps</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>combined-inflection</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>‘ He 's done us proud , as well,’ says Granville .</td>\n","      <td>do someone proud</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>combined-inflection</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root .</td>\n","      <td>take root</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>48390</th>\n","      <td>Many also have second or third jobs to make ends meet .</td>\n","      <td>make ends meet</td>\n","      <td>0.854973</td>\n","      <td>i</td>\n","      <td>test</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>48391</th>\n","      <td>Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection</td>\n","      <td>bear in mind</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>48392</th>\n","      <td>Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training .</td>\n","      <td>as a rule</td>\n","      <td>1.000000</td>\n","      <td>l</td>\n","      <td>training</td>\n","      <td>deletion-determiner</td>\n","    </tr>\n","    <tr>\n","      <th>48393</th>\n","      <td>Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy .</td>\n","      <td>jack of all trades</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>identical</td>\n","    </tr>\n","    <tr>\n","      <th>48394</th>\n","      <td>The Government flies these kites of disinformation then people feel grateful when they do n't happen .</td>\n","      <td>fly a kite</td>\n","      <td>1.000000</td>\n","      <td>i</td>\n","      <td>training</td>\n","      <td>combined-inflection</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>48395 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92a2a18b-c1e9-43ac-9789-10f5062345f8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-92a2a18b-c1e9-43ac-9789-10f5062345f8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-92a2a18b-c1e9-43ac-9789-10f5062345f8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                                                                                                                                 sentence_0  \\\n","0                               For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?   \n","1                                                                                                                                       I 'd keep him well in the running .   \n","2                                                                                                                    He gives me the creeps , so I looked round , hmm hmm .   \n","3                                                                                                                        ‘ He 's done us proud , as well,’ says Granville .   \n","4                       People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root .   \n","...                                                                                                                                                                     ...   \n","48390                                                                                                               Many also have second or third jobs to make ends meet .   \n","48391                                           Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection   \n","48392                Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training .   \n","48393  Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy .   \n","48394                                                                The Government flies these kites of disinformation then people feel grateful when they do n't happen .   \n","\n","                         idiom  confidence label     split  \\\n","0         off the beaten track    1.000000     i  training   \n","1               in the running    0.770109     i  training   \n","2      give someone the creeps    1.000000     i  training   \n","3             do someone proud    1.000000     i  training   \n","4                    take root    1.000000     i  training   \n","...                        ...         ...   ...       ...   \n","48390           make ends meet    0.854973     i      test   \n","48391             bear in mind    1.000000     i  training   \n","48392                as a rule    1.000000     l  training   \n","48393       jack of all trades    1.000000     i  training   \n","48394               fly a kite    1.000000     i  training   \n","\n","              variant_type  \n","0                identical  \n","1                identical  \n","2      combined-inflection  \n","3      combined-inflection  \n","4                identical  \n","...                    ...  \n","48390            identical  \n","48391            identical  \n","48392  deletion-determiner  \n","48393            identical  \n","48394  combined-inflection  \n","\n","[48395 rows x 6 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_data = pd.read_csv(data_file)\n","df_data"],"id":"fe3ba613"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6f7355ab"},"outputs":[],"source":["columns=['sentence_0', 'idiom', 'confidence', 'label', 'split', 'variant_type']"],"id":"6f7355ab"},{"cell_type":"markdown","metadata":{"id":"C52nDzJG09z6"},"source":["## Prepare & save the train, dev & test sets"],"id":"C52nDzJG09z6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8XjnVNz2PuK"},"outputs":[],"source":["label_to_id = {'i': 0, 'l': 1}"],"id":"F8XjnVNz2PuK"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1657806539044,"user":{"displayName":"Darshan Adiga Haniya Narayana","userId":"13149745487125032133"},"user_tz":-60},"id":"DBTb2rUkwJK8","outputId":"b94ffaa9-84a5-467b-8122-6b567308f014"},"outputs":[{"data":{"text/plain":["training       38715\n","test            4840\n","development     4840\n","Name: split, dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_data['split'].value_counts()"],"id":"DBTb2rUkwJK8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OqaBa6Pl004w"},"outputs":[],"source":["df_tmp = df_data[['sentence_0', 'label', 'split']]\n","\n","df_train = df_tmp[df_tmp['split'] == 'training']\n","df_dev = df_tmp[df_tmp['split'] == 'development']\n","df_test = df_tmp[df_tmp['split'] == 'test']\n","\n","def clean_df(df):\n","    \"\"\"Clean each of the datasets\"\"\"\n","    df = df.drop(columns=['split'])\n","    df['label'] = df['label'].map(label_to_id)\n","    return df\n","\n","# Clean the datasets\n","df_train, df_dev, df_test = [clean_df(df) for df in [df_train, df_dev, df_test]]"],"id":"OqaBa6Pl004w"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":622,"status":"ok","timestamp":1657806539656,"user":{"displayName":"Darshan Adiga Haniya Narayana","userId":"13149745487125032133"},"user_tz":-60},"id":"AoN6C7nj1z8E","outputId":"605daebb-3795-4c69-f316-2ca9d4852ca0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved the files to experiments/exp0/tmp/\n"]}],"source":["# Save data to tmp files\n","train_csv = tmp_dir + 'train.csv'\n","dev_csv = tmp_dir + 'dev.csv'\n","test_csv = tmp_dir + 'test.csv'\n","\n","df_train.to_csv(train_csv, index=False)\n","df_dev.to_csv(dev_csv, index=False)\n","df_test.to_csv(test_csv, index=False)\n","print(f'Saved the files to {tmp_dir}')"],"id":"AoN6C7nj1z8E"},{"cell_type":"markdown","metadata":{"id":"1oSMKsaa4jU0"},"source":["# Training & Evaluation"],"id":"1oSMKsaa4jU0"},{"cell_type":"markdown","metadata":{"id":"PWUrf9a44nfL"},"source":["## Fine-tune, Save & Evaluate\n","\n","TODO: Note that `dev_csv` file is not used anywhere here!"],"id":"PWUrf9a44nfL"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pY7soeu042NQ","outputId":"9dfb6ba8-fa90-4e31-de46-2b8b18d94170"},"outputs":[{"name":"stdout","output_type":"stream","text":["07/14/2022 13:49:06 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n","07/14/2022 13:49:06 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n","_n_gpu=0,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_steps=500,\n","evaluation_strategy=IntervalStrategy.EPOCH,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","greater_is_better=True,\n","group_by_length=False,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=-1,\n","log_on_each_node=True,\n","logging_dir=runs/Jul14_13-49-06_ec4a5acc10d9,\n","logging_first_step=False,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=f1,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=6.0,\n","output_dir=experiments/exp0/models/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=32,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=experiments/exp0/models/,\n","save_steps=500,\n","save_strategy=IntervalStrategy.EPOCH,\n","save_total_limit=3,\n","seed=26,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","07/14/2022 13:49:06 - INFO - __main__ -   load a local file for train: experiments/exp0/tmp/train.csv\n","07/14/2022 13:49:06 - INFO - __main__ -   load a local file for validation: experiments/exp0/tmp/dev.csv\n","07/14/2022 13:49:06 - INFO - __main__ -   load a local file for test: experiments/exp0/tmp/test.csv\n","07/14/2022 13:49:07 - WARNING - datasets.builder -   Using custom data configuration default-717fc87c09e57d9d\n","Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-717fc87c09e57d9d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n","0 tables [00:00, ? tables/s]/usr/local/lib/python3.7/dist-packages/tqdm/std.py:1133: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  for obj in iterable:\n","/usr/local/lib/python3.7/dist-packages/tqdm/std.py:1133: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  for obj in iterable:\n","Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-717fc87c09e57d9d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1590] 2022-07-14 13:49:08,056 >> https://huggingface.co/bert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpeef69w60\n","Downloading: 100% 570/570 [00:00<00:00, 252kB/s]\n","[INFO|file_utils.py:1594] 2022-07-14 13:49:08,174 >> storing https://huggingface.co/bert-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|file_utils.py:1602] 2022-07-14 13:49:08,174 >> creating metadata file for /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:517] 2022-07-14 13:49:08,175 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:553] 2022-07-14 13:49:08,176 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|configuration_utils.py:517] 2022-07-14 13:49:08,285 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:553] 2022-07-14 13:49:08,286 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.7.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|file_utils.py:1590] 2022-07-14 13:49:08,406 >> https://huggingface.co/bert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvgcf9wx1\n","Downloading: 100% 213k/213k [00:00<00:00, 3.06MB/s]\n","[INFO|file_utils.py:1594] 2022-07-14 13:49:08,619 >> storing https://huggingface.co/bert-base-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|file_utils.py:1602] 2022-07-14 13:49:08,620 >> creating metadata file for /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|file_utils.py:1590] 2022-07-14 13:49:08,752 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp80xnz4hs\n","Downloading: 100% 436k/436k [00:00<00:00, 5.10MB/s]\n","[INFO|file_utils.py:1594] 2022-07-14 13:49:08,982 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|file_utils.py:1602] 2022-07-14 13:49:08,982 >> creating metadata file for /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|file_utils.py:1590] 2022-07-14 13:49:09,343 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpl0dvyjln\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 15.9kB/s]\n","[INFO|file_utils.py:1594] 2022-07-14 13:49:09,466 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|file_utils.py:1602] 2022-07-14 13:49:09,467 >> creating metadata file for /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|tokenization_utils_base.py:1717] 2022-07-14 13:49:09,467 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|tokenization_utils_base.py:1717] 2022-07-14 13:49:09,467 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|tokenization_utils_base.py:1717] 2022-07-14 13:49:09,467 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1717] 2022-07-14 13:49:09,467 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1717] 2022-07-14 13:49:09,467 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|file_utils.py:1590] 2022-07-14 13:49:09,695 >> https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_w5chccw\n","Downloading: 100% 436M/436M [00:12<00:00, 34.8MB/s]\n","[INFO|file_utils.py:1594] 2022-07-14 13:49:22,380 >> storing https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[INFO|file_utils.py:1602] 2022-07-14 13:49:22,381 >> creating metadata file for /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[INFO|modeling_utils.py:1152] 2022-07-14 13:49:22,381 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[WARNING|modeling_utils.py:1328] 2022-07-14 13:49:24,208 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1339] 2022-07-14 13:49:24,209 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","07/14/2022 13:49:24 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fb5e3bea200> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","100% 39/39 [00:04<00:00,  8.11ba/s]\n","100% 5/5 [00:00<00:00,  9.30ba/s]\n","100% 5/5 [00:00<00:00,  9.19ba/s]\n","07/14/2022 13:49:30 - INFO - __main__ -   Sample 35652 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 1109, 13094, 1916, 1965, 1579, 3471, 1120, 1103, 1334, 1104, 1103, 23458, 113, 1170, 1103, 14516, 25043, 7562, 1138, 1151, 6561, 114, 1118, 16366, 170, 13094, 1113, 1296, 3111, 1104, 1594, 1643, 15060, 1107, 170, 10012, 2447, 1506, 1103, 9346, 1104, 1103, 23458, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'sentence_0': 'The knotting process always begins at the side of the rug ( after the selvedges have been secured ) by tying a knot on each pair of warp strands in a horizontal direction across the width of the rug .', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","07/14/2022 13:49:30 - INFO - __main__ -   Sample 3719 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 2545, 1144, 1688, 170, 7053, 1526, 1105, 1117, 6600, 3001, 1138, 10558, 5409, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'sentence_0': 'Tom has joined a laughter club and his stress levels have decreased significantly .', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","07/14/2022 13:49:30 - INFO - __main__ -   Sample 8380 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 138, 1248, 1137, 1177, 1196, 1544, 1159, 9784, 1431, 1138, 1151, 2044, 1105, 3126, 1112, 6242, 2690, 1855, 1103, 2112, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0, 'sentence_0': 'A second or so before half time Bradford should have been dead and buried as Tommy Jones hit the post .', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","[INFO|trainer.py:515] 2022-07-14 13:49:30,147 >> The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence_0.\n","[INFO|trainer.py:1147] 2022-07-14 13:49:30,192 >> ***** Running training *****\n","[INFO|trainer.py:1148] 2022-07-14 13:49:30,192 >>   Num examples = 38715\n","[INFO|trainer.py:1149] 2022-07-14 13:49:30,192 >>   Num Epochs = 6\n","[INFO|trainer.py:1150] 2022-07-14 13:49:30,192 >>   Instantaneous batch size per device = 32\n","[INFO|trainer.py:1151] 2022-07-14 13:49:30,192 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n","[INFO|trainer.py:1152] 2022-07-14 13:49:30,192 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1153] 2022-07-14 13:49:30,192 >>   Total optimization steps = 7260\n","  6% 448/7260 [4:59:27<75:56:52, 40.14s/it]"]}],"source":["# Run the helper script that trains, saves the sentence classification model\n","!python exp_helpers/run_glue_f1_macro.py \\\n","        --model_name_or_path $exp_model \\\n","    \t--do_train \\\n","    \t--do_eval \\\n","        --do_predict \\\n","    \t--max_seq_length 128 \\\n","    \t--per_device_train_batch_size 32 \\\n","    \t--learning_rate 2e-5 \\\n","    \t--num_train_epochs 6 \\\n","    \t--evaluation_strategy \"epoch\" \\\n","    \t--output_dir $model_checkpoint_dir \\\n","    \t--seed $exp_seed \\\n","    \t--train_file      $train_csv \\\n","    \t--validation_file $dev_csv \\\n","        --test_file       $test_csv \\\n","        --test_metrics \\\n","        --evaluation_strategy \"epoch\" \\\n","        --save_strategy \"epoch\"  \\\n","        --load_best_model_at_end \\\n","        --metric_for_best_model \"f1\" \\\n","        --save_total_limit 3"],"id":"pY7soeu042NQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7pMZy0fL0cY"},"outputs":[],"source":[""],"id":"i7pMZy0fL0cY"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"exp0.ipynb","provenance":[{"file_id":"https://github.com/DarshanAdiga/idiom_principle_on_magpie_corpus/blob/main/notebooks/data_utils.ipynb","timestamp":1657750032837}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}