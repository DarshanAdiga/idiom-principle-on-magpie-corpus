{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a531b3",
   "metadata": {},
   "source": [
    "## Idiom Vocab Helper \n",
    "\n",
    "This notebook creates a list of all the know idioms from the given MAGPIE dataset and creates Single-Tokens for them. This list of single-tokens will be inserted into the vocabulary of a LM using **model_download_add_tokensipynb**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467965db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Should I create a list of idioms from the entire data(combined training, dev & test sets)? Would it still be \n",
    "# called zero-shot if I do so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce27cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth=500\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba44eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../'\n",
    "base_dir = root_dir + 'data/magpie/'\n",
    "data_file = base_dir + 'MAGPIE_filtered_split_typebased.jsonl'\n",
    "\n",
    "output_token_dir = root_dir + 'data/token_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e913935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>context</th>\n",
       "      <th>document_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>id</th>\n",
       "      <th>idiom</th>\n",
       "      <th>judgment_count</th>\n",
       "      <th>label</th>\n",
       "      <th>label_distribution</th>\n",
       "      <th>non_standard_usage_explanations</th>\n",
       "      <th>offsets</th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>split</th>\n",
       "      <th>variant_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Please , can we close the doggy postbag for now !, Remember that RUNNING is looking for all kinds of safety tips ., For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?, FITNESS CLINIC, DIET]</td>\n",
       "      <td>AR7</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>0</td>\n",
       "      <td>off the beaten track</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[117, 120], [125, 131], [132, 137]]</td>\n",
       "      <td>626</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770109</td>\n",
       "      <td>[But it 's a selfish family , I 'd say ., They take what they want ., I 'd keep him well in the running ., Then of course there 's Desmond 's wife — I 'd forgotten her ., I did n't get much of an impression of her .]</td>\n",
       "      <td>H9D</td>\n",
       "      <td>W fict prose</td>\n",
       "      <td>1</td>\n",
       "      <td>in the running</td>\n",
       "      <td>10</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.770109357701371, 'l': 0.22989064229862802, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[19, 21], [26, 33]]</td>\n",
       "      <td>1520</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[And I looked behind , and he was just sitting there staring like that ., Oh my god ., He gives me the creeps , so I looked round , hmm hmm ., I mean , what is she doing ?, What does she want ?]</td>\n",
       "      <td>KNY</td>\n",
       "      <td>S conv</td>\n",
       "      <td>2</td>\n",
       "      <td>give someone the creeps</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[3, 8], [9, 11], [16, 22]]</td>\n",
       "      <td>1850</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Especially this year ., Makes me hair stand on end just thinking about it.’, ‘ He 's done us proud , as well,’ says Granville ., ‘ He had the chance to go to the States with them but he said , ‘ No’ ., Other commitments.’]</td>\n",
       "      <td>CK4</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>3</td>\n",
       "      <td>do someone proud</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[8, 12], [13, 15], [16, 21]]</td>\n",
       "      <td>613</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Rather , what is needed most is a new way of thinking – new “ software ” ( though effective “ hard ” green technologies also are essential ) ., As we saw in the postcommunist world , changing attitudes is often the hardest problem of all ., People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root ., , ]</td>\n",
       "      <td>p63d3559</td>\n",
       "      <td>PMB</td>\n",
       "      <td>4</td>\n",
       "      <td>take root</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[136, 140], [141, 145]]</td>\n",
       "      <td>15</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48390</th>\n",
       "      <td>0.854973</td>\n",
       "      <td>[The running of multiple sessions has been another means of saving which , though not always a problem , has led to truncated teaching sessions , late - coming and absenteeism on the part of teachers and pupils ., Teacher absenteeism is also exacerbated by general shortages of goods and services : teachers , like other employees , can spend half their days chasing scarce consumer goods for their families , instead of being in the classroom ., Many also have second or third jobs to make ends ...</td>\n",
       "      <td>B12</td>\n",
       "      <td>W ac:polit law edu</td>\n",
       "      <td>48390</td>\n",
       "      <td>make ends meet</td>\n",
       "      <td>9</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.8549734944978761, 'l': 0.145026505502123, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[39, 43], [44, 48], [49, 53]]</td>\n",
       "      <td>246</td>\n",
       "      <td>test</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48391</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[you understand the process ?, Yeah , yeah, Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection, Yeah, right , another thing , we wanna get more quotes , right]</td>\n",
       "      <td>KDJ</td>\n",
       "      <td>S conv</td>\n",
       "      <td>48391</td>\n",
       "      <td>bear in mind</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[71, 75], [76, 78], [79, 83]]</td>\n",
       "      <td>207</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48392</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[The same implications attach to the playing of games or the membership of clubs and so on , although what is of even more interest are the ' unwritten ' rules which underwrite the more formal , quasi - legal , ones ., Without unwritten rules civilised life would be impossible ., Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training ., Many were originally instinctive and , to that limited extent ,...</td>\n",
       "      <td>CM8</td>\n",
       "      <td>W ac:humanities arts</td>\n",
       "      <td>48392</td>\n",
       "      <td>as a rule</td>\n",
       "      <td>4</td>\n",
       "      <td>l</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.0, 'l': 1.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35, 37], [38, 43]]</td>\n",
       "      <td>865</td>\n",
       "      <td>training</td>\n",
       "      <td>deletion-determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48393</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[A manufacturer can work closely with its suppliers , co - operating on the development of new components , for instance ., It is like being part of the same company , but without the drawbacks ., Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy ., From the supplier 's point of view , the relationship is better than simply one based on contracts , price and open bidding ., Though...</td>\n",
       "      <td>ABJ</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>48393</td>\n",
       "      <td>jack of all trades</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[27, 31], [32, 34], [35, 38], [39, 45]]</td>\n",
       "      <td>4073</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48394</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[That 's optimistic ., The announcement that National Insurance rates are to stay the same is more window - dressing , I think ., The Government flies these kites of disinformation then people feel grateful when they do n't happen ., The Chancellor has shifted a few factors around , that 's all ., Brilliant Brown goes for the jugular]</td>\n",
       "      <td>CEK</td>\n",
       "      <td>W newsp other: social</td>\n",
       "      <td>48394</td>\n",
       "      <td>fly a kite</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[15, 20], [27, 32]]</td>\n",
       "      <td>5616</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48395 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence  \\\n",
       "0        1.000000   \n",
       "1        0.770109   \n",
       "2        1.000000   \n",
       "3        1.000000   \n",
       "4        1.000000   \n",
       "...           ...   \n",
       "48390    0.854973   \n",
       "48391    1.000000   \n",
       "48392    1.000000   \n",
       "48393    1.000000   \n",
       "48394    1.000000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0                                                                                                                                                                                                                                  [Please , can we close the doggy postbag for now !, Remember that RUNNING is looking for all kinds of safety tips ., For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?, FITNESS CLINIC, DIET]   \n",
       "1                                                                                                                                                                                                                                                                                                 [But it 's a selfish family , I 'd say ., They take what they want ., I 'd keep him well in the running ., Then of course there 's Desmond 's wife — I 'd forgotten her ., I did n't get much of an impression of her .]   \n",
       "2                                                                                                                                                                                                                                                                                                                       [And I looked behind , and he was just sitting there staring like that ., Oh my god ., He gives me the creeps , so I looked round , hmm hmm ., I mean , what is she doing ?, What does she want ?]   \n",
       "3                                                                                                                                                                                                                                                                                          [Especially this year ., Makes me hair stand on end just thinking about it.’, ‘ He 's done us proud , as well,’ says Granville ., ‘ He had the chance to go to the States with them but he said , ‘ No’ ., Other commitments.’]   \n",
       "4                                                                                                               [Rather , what is needed most is a new way of thinking – new “ software ” ( though effective “ hard ” green technologies also are essential ) ., As we saw in the postcommunist world , changing attitudes is often the hardest problem of all ., People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root ., , ]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "48390  [The running of multiple sessions has been another means of saving which , though not always a problem , has led to truncated teaching sessions , late - coming and absenteeism on the part of teachers and pupils ., Teacher absenteeism is also exacerbated by general shortages of goods and services : teachers , like other employees , can spend half their days chasing scarce consumer goods for their families , instead of being in the classroom ., Many also have second or third jobs to make ends ...   \n",
       "48391                                                                                                                                                                                                                                                                             [you understand the process ?, Yeah , yeah, Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection, Yeah, right , another thing , we wanna get more quotes , right]   \n",
       "48392  [The same implications attach to the playing of games or the membership of clubs and so on , although what is of even more interest are the ' unwritten ' rules which underwrite the more formal , quasi - legal , ones ., Without unwritten rules civilised life would be impossible ., Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training ., Many were originally instinctive and , to that limited extent ,...   \n",
       "48393  [A manufacturer can work closely with its suppliers , co - operating on the development of new components , for instance ., It is like being part of the same company , but without the drawbacks ., Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy ., From the supplier 's point of view , the relationship is better than simply one based on contracts , price and open bidding ., Though...   \n",
       "48394                                                                                                                                                                     [That 's optimistic ., The announcement that National Insurance rates are to stay the same is more window - dressing , I think ., The Government flies these kites of disinformation then people feel grateful when they do n't happen ., The Chancellor has shifted a few factors around , that 's all ., Brilliant Brown goes for the jugular]   \n",
       "\n",
       "      document_id                  genre     id                    idiom  \\\n",
       "0             AR7             W pop lore      0     off the beaten track   \n",
       "1             H9D           W fict prose      1           in the running   \n",
       "2             KNY                 S conv      2  give someone the creeps   \n",
       "3             CK4             W pop lore      3         do someone proud   \n",
       "4        p63d3559                    PMB      4                take root   \n",
       "...           ...                    ...    ...                      ...   \n",
       "48390         B12     W ac:polit law edu  48390           make ends meet   \n",
       "48391         KDJ                 S conv  48391             bear in mind   \n",
       "48392         CM8   W ac:humanities arts  48392                as a rule   \n",
       "48393         ABJ             W pop lore  48393       jack of all trades   \n",
       "48394         CEK  W newsp other: social  48394               fly a kite   \n",
       "\n",
       "       judgment_count label  \\\n",
       "0                   3     i   \n",
       "1                  10     i   \n",
       "2                   3     i   \n",
       "3                   3     i   \n",
       "4                   3     i   \n",
       "...               ...   ...   \n",
       "48390               9     i   \n",
       "48391               3     i   \n",
       "48392               4     l   \n",
       "48393               3     i   \n",
       "48394               3     i   \n",
       "\n",
       "                                                                     label_distribution  \\\n",
       "0                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "1      {'?': 0.0, 'f': 0.0, 'i': 0.770109357701371, 'l': 0.22989064229862802, 'o': 0.0}   \n",
       "2                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "3                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "4                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "...                                                                                 ...   \n",
       "48390   {'?': 0.0, 'f': 0.0, 'i': 0.8549734944978761, 'l': 0.145026505502123, 'o': 0.0}   \n",
       "48391                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "48392                                {'?': 0.0, 'f': 0.0, 'i': 0.0, 'l': 1.0, 'o': 0.0}   \n",
       "48393                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "48394                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "\n",
       "      non_standard_usage_explanations  \\\n",
       "0                                  []   \n",
       "1                                  []   \n",
       "2                                  []   \n",
       "3                                  []   \n",
       "4                                  []   \n",
       "...                               ...   \n",
       "48390                              []   \n",
       "48391                              []   \n",
       "48392                              []   \n",
       "48393                              []   \n",
       "48394                              []   \n",
       "\n",
       "                                        offsets  sentence_no     split  \\\n",
       "0          [[117, 120], [125, 131], [132, 137]]          626  training   \n",
       "1                          [[19, 21], [26, 33]]         1520  training   \n",
       "2                   [[3, 8], [9, 11], [16, 22]]         1850  training   \n",
       "3                 [[8, 12], [13, 15], [16, 21]]          613  training   \n",
       "4                      [[136, 140], [141, 145]]           15  training   \n",
       "...                                         ...          ...       ...   \n",
       "48390            [[39, 43], [44, 48], [49, 53]]          246      test   \n",
       "48391            [[71, 75], [76, 78], [79, 83]]          207  training   \n",
       "48392                      [[35, 37], [38, 43]]          865  training   \n",
       "48393  [[27, 31], [32, 34], [35, 38], [39, 45]]         4073  training   \n",
       "48394                      [[15, 20], [27, 32]]         5616  training   \n",
       "\n",
       "              variant_type  \n",
       "0                identical  \n",
       "1                identical  \n",
       "2      combined-inflection  \n",
       "3      combined-inflection  \n",
       "4                identical  \n",
       "...                    ...  \n",
       "48390            identical  \n",
       "48391            identical  \n",
       "48392  deletion-determiner  \n",
       "48393            identical  \n",
       "48394  combined-inflection  \n",
       "\n",
       "[48395 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_json(data_file, lines=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c402dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Considering the entire data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d53104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           off the beaten track\n",
       "1                 in the running\n",
       "2        give someone the creeps\n",
       "3               do someone proud\n",
       "4                      take root\n",
       "                  ...           \n",
       "48390             make ends meet\n",
       "48391               bear in mind\n",
       "48392                  as a rule\n",
       "48393         jack of all trades\n",
       "48394                 fly a kite\n",
       "Name: idiom, Length: 48395, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6032f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     25308\n",
       "False    23087\n",
       "Name: idiom_exact_match, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the values in 'idiom' column are used exactly as it is in the sentece\n",
    "df_data['idiom_exact_match'] = df_data.apply(lambda row: row['idiom'] in row['context'][2], axis=1)\n",
    "df_data['idiom_exact_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d66e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>idiom_exact_match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">i</th>\n",
       "      <th>True</th>\n",
       "      <td>21124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>15204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">l</th>\n",
       "      <th>False</th>\n",
       "      <td>7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "label idiom_exact_match       \n",
       "i     True               21124\n",
       "      False              15204\n",
       "l     False               7883\n",
       "      True                4184"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = df_data[[ 'label', 'idiom_exact_match']].value_counts()\n",
    "pd.DataFrame(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4959229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "trans = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def idiom_to_token(idiom_phrase):\n",
    "    \"\"\"Process the given idiom phrase and convert into a string token\"\"\"\n",
    "    idiom_phrase = idiom_phrase.translate(trans)\n",
    "    idiom_phrase = idiom_phrase.lower().replace(' ', '').lstrip().rstrip()\n",
    "    return 'ID' + idiom_phrase + 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7f00d",
   "metadata": {},
   "source": [
    "### Idioms are not matching exactly\n",
    "How to deal with ~50% of the examples where the value of the column 'idiom' is not matching exactly with that of its usage in the sentence?\n",
    "\n",
    "**Option-1**\n",
    "Just convert the values in 'idiom' column to tokens, irrespective of how they are used in the sentence. In other words, this approach will make the LM model to learn only those tokens which have an exact match. This leads to incomplete experiment, because we will capture only 50% of MWEs as single tokens.\n",
    "\n",
    "**Option-2**\n",
    "Use the **offsets** column and extract the actual MWE from the sentence. This will capture all possible MWEs in the data, but the number of unique tokens would be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7132e",
   "metadata": {},
   "source": [
    "### Option-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11bd7e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in the long run                200\n",
       "come to terms with             174\n",
       "with a view to                 173\n",
       "bear in mind                   172\n",
       "for the time being             171\n",
       "                              ... \n",
       "king of beasts                   1\n",
       "fit to be tied                   1\n",
       "start off on the right foot      1\n",
       "in apple-pie order               1\n",
       "ring off the hook                1\n",
       "Name: idiom, Length: 1738, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_data['idiom'].value_counts())\n",
    "df_data['idiom'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210ea7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33561</th>\n",
       "      <td>big hitter</td>\n",
       "      <td>IDbighitterID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17342</th>\n",
       "      <td>nine times out of ten</td>\n",
       "      <td>IDninetimesoutoftenID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19221</th>\n",
       "      <td>out of the question</td>\n",
       "      <td>IDoutofthequestionID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13362</th>\n",
       "      <td>spot on</td>\n",
       "      <td>IDspotonID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>go down like a lead balloon</td>\n",
       "      <td>IDgodownlikealeadballoonID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17383</th>\n",
       "      <td>go hand in hand</td>\n",
       "      <td>IDgohandinhandID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39300</th>\n",
       "      <td>on someone's mind</td>\n",
       "      <td>IDonsomeonesmindID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46129</th>\n",
       "      <td>make history</td>\n",
       "      <td>IDmakehistoryID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37862</th>\n",
       "      <td>all hell broke loose</td>\n",
       "      <td>IDallhellbrokelooseID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>in the black</td>\n",
       "      <td>IDintheblackID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             idiom                 idiom_token\n",
       "33561                   big hitter               IDbighitterID\n",
       "17342        nine times out of ten       IDninetimesoutoftenID\n",
       "19221          out of the question        IDoutofthequestionID\n",
       "13362                      spot on                  IDspotonID\n",
       "34521  go down like a lead balloon  IDgodownlikealeadballoonID\n",
       "17383              go hand in hand            IDgohandinhandID\n",
       "39300            on someone's mind          IDonsomeonesmindID\n",
       "46129                 make history             IDmakehistoryID\n",
       "37862         all hell broke loose       IDallhellbrokelooseID\n",
       "6441                  in the black              IDintheblackID"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom_token'] = df_data['idiom'].map(idiom_to_token)\n",
    "df_data[['idiom', 'idiom_token']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9855bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the 1738 tokens to ../data/token_files/option1_idiom_tokens.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the list of idioms\n",
    "option_1_idiom_token_file = output_token_dir + 'option1_idiom_tokens.txt'\n",
    "unique_tokens = df_data['idiom_token'].unique()\n",
    "np.savetxt(option_1_idiom_token_file, unique_tokens, fmt='%s', header='')\n",
    "print(f'Saved the {unique_tokens.shape[0]} tokens to {option_1_idiom_token_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6d26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the <idiom,token> pairs to ../data/token_files/option1_idioms.csv\n"
     ]
    }
   ],
   "source": [
    "# Save both idiom and its token; to be used for replacing the idioms in datasets\n",
    "option_1_idioms_file = output_token_dir + 'option1_idioms.csv'\n",
    "df_idioms = df_data[['idiom', 'idiom_token']].drop_duplicates(subset='idiom_token', keep=\"first\")\n",
    "df_idioms.to_csv(option_1_idioms_file, index=False)\n",
    "print(f'Saved the <idiom,token> pairs to {option_1_idioms_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474500c",
   "metadata": {},
   "source": [
    "### Option-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23dd0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_idiom_phrase(row):\n",
    "    sentence = row['context'][2]\n",
    "    # Pair of start and end positions of an MWE within the sentence\n",
    "    offsets = row['offsets']\n",
    "    # Being crude here, so that the exact usage of the MWE is captured\n",
    "    start = offsets[0][0] # Start of the first word\n",
    "    end = offsets[-1][1] # End of the last word\n",
    "    return sentence[start:end]\n",
    "# Extract the MWE from sentences\n",
    "df_data['idiom_phrase'] = df_data.apply(lambda row: extract_idiom_phrase(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa3b6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45092</th>\n",
       "      <td>in the raw</td>\n",
       "      <td>in the raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41551</th>\n",
       "      <td>across the board</td>\n",
       "      <td>across the board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37543</th>\n",
       "      <td>in the club</td>\n",
       "      <td>in a night club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>on paper</td>\n",
       "      <td>on kitchen paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32101</th>\n",
       "      <td>one of those things</td>\n",
       "      <td>one of those things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37476</th>\n",
       "      <td>come to mind</td>\n",
       "      <td>come to mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41782</th>\n",
       "      <td>in the long term</td>\n",
       "      <td>in the long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>keep tabs on</td>\n",
       "      <td>keep tabs on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31842</th>\n",
       "      <td>come of age</td>\n",
       "      <td>come of age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9430</th>\n",
       "      <td>in the works</td>\n",
       "      <td>in the work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     idiom         idiom_phrase\n",
       "45092           in the raw           in the raw\n",
       "41551     across the board     across the board\n",
       "37543          in the club      in a night club\n",
       "20337             on paper     on kitchen paper\n",
       "32101  one of those things  one of those things\n",
       "37476         come to mind         come to mind\n",
       "41782     in the long term     in the long term\n",
       "2638          keep tabs on         keep tabs on\n",
       "31842          come of age          come of age\n",
       "9430          in the works          in the work"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[['idiom', 'idiom_phrase']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1c7e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom_phrase</th>\n",
       "      <th>idiom_phrase_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>have a few</td>\n",
       "      <td>IDhaveafewID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7564</th>\n",
       "      <td>once and for all</td>\n",
       "      <td>IDonceandforallID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41371</th>\n",
       "      <td>begs the question</td>\n",
       "      <td>IDbegsthequestionID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26553</th>\n",
       "      <td>rose from the ashes</td>\n",
       "      <td>IDrosefromtheashesID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12720</th>\n",
       "      <td>hold all the aces</td>\n",
       "      <td>IDholdalltheacesID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>bearing in mind</td>\n",
       "      <td>IDbearinginmindID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20012</th>\n",
       "      <td>breaking new ground</td>\n",
       "      <td>IDbreakingnewgroundID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>off the hook</td>\n",
       "      <td>IDoffthehookID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34768</th>\n",
       "      <td>fun - and - games</td>\n",
       "      <td>IDfunandgamesID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39410</th>\n",
       "      <td>laughing stock</td>\n",
       "      <td>IDlaughingstockID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              idiom_phrase     idiom_phrase_token\n",
       "8321            have a few           IDhaveafewID\n",
       "7564      once and for all      IDonceandforallID\n",
       "41371    begs the question    IDbegsthequestionID\n",
       "26553  rose from the ashes   IDrosefromtheashesID\n",
       "12720    hold all the aces     IDholdalltheacesID\n",
       "946        bearing in mind      IDbearinginmindID\n",
       "20012  breaking new ground  IDbreakingnewgroundID\n",
       "1678          off the hook         IDoffthehookID\n",
       "34768    fun - and - games        IDfunandgamesID\n",
       "39410       laughing stock      IDlaughingstockID"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom_phrase_token'] = df_data['idiom_phrase'].map(idiom_to_token)\n",
    "df_data[['idiom_phrase', 'idiom_phrase_token']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e186c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the 10871 tokens to ../data/token_files/option2_idiom_tokens.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the list of idioms\n",
    "option_2_idiom_token_file = output_token_dir + 'option2_idiom_tokens.txt'\n",
    "unique_tokens = df_data['idiom_phrase_token'].unique()\n",
    "np.savetxt(option_2_idiom_token_file, unique_tokens, fmt='%s', header='')\n",
    "print(f'Saved the {unique_tokens.shape[0]} tokens to {option_2_idiom_token_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8265054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>off the beaten track</td>\n",
       "      <td>IDoffthebeatentrackID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the running</td>\n",
       "      <td>IDintherunningID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gives me the creeps</td>\n",
       "      <td>IDgivesmethecreepsID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>done us proud</td>\n",
       "      <td>IDdoneusproudID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take root</td>\n",
       "      <td>IDtakerootID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  idiom            idiom_token\n",
       "0  off the beaten track  IDoffthebeatentrackID\n",
       "1        in the running       IDintherunningID\n",
       "2   gives me the creeps   IDgivesmethecreepsID\n",
       "3         done us proud        IDdoneusproudID\n",
       "4             take root           IDtakerootID"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns, to keep it consistent\n",
    "df_data = df_data[['idiom_phrase', 'idiom_phrase_token']]\n",
    "df_data = df_data.rename(columns={'idiom_phrase':'idiom', 'idiom_phrase_token':'idiom_token'})\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31ba0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the <idiom,token> pairs to ../data/token_files/option2_idioms.csv\n"
     ]
    }
   ],
   "source": [
    "# Save both idiom phrase and its token; to be used for replacing the idioms in datasets\n",
    "option_2_idioms_file = output_token_dir + 'option2_idioms.csv'\n",
    "df_idioms = df_data[['idiom', 'idiom_token']].drop_duplicates(subset='idiom_token', keep=\"first\")\n",
    "df_idioms.to_csv(option_2_idioms_file, index=False)\n",
    "print(f'Saved the <idiom,token> pairs to {option_2_idioms_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b89a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB_VENV",
   "language": "python",
   "name": "lab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
