{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15c424c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/darshan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9ec56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "magpie_token_file = '../data/token_files/option1_idioms.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf65236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>off the beaten track</td>\n",
       "      <td>IDoffthebeatentrackID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the running</td>\n",
       "      <td>IDintherunningID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>give someone the creeps</td>\n",
       "      <td>IDgivesomeonethecreepsID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do someone proud</td>\n",
       "      <td>IDdosomeoneproudID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take root</td>\n",
       "      <td>IDtakerootID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     idiom               idiom_token\n",
       "0     off the beaten track     IDoffthebeatentrackID\n",
       "1           in the running          IDintherunningID\n",
       "2  give someone the creeps  IDgivesomeonethecreepsID\n",
       "3         do someone proud        IDdosomeoneproudID\n",
       "4                take root              IDtakerootID"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_magpie_tokens = pd.read_csv(magpie_token_file)\n",
    "df_magpie_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298172dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>CompScale</th>\n",
       "      <th>CompType</th>\n",
       "      <th>MeanS1</th>\n",
       "      <th>MeanS2</th>\n",
       "      <th>MeanS3</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>SynonymsS1</th>\n",
       "      <th>SynonymsS2</th>\n",
       "      <th>SynonymsS3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car park</td>\n",
       "      <td>PC</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.90</td>\n",
       "      <td>parking lot;parking lot;parking garage;vehicle...</td>\n",
       "      <td>garage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dream ticket</td>\n",
       "      <td>NC</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.90</td>\n",
       "      <td>perfect combination;golden ticket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ideal</td>\n",
       "      <td>opportunity;chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case study</td>\n",
       "      <td>C</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.08</td>\n",
       "      <td>example;specific example;medical trial;analysis</td>\n",
       "      <td>history;documentation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dutch courage</td>\n",
       "      <td>PC</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70</td>\n",
       "      <td>alcohol;liquid courage;liquid courage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hitting the bottle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cash cow</td>\n",
       "      <td>NC</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>gold mine;money maker;moneymaker;moneymaker;st...</td>\n",
       "      <td>income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound CompScale  CompType  MeanS1  MeanS2  MeanS3  \\\n",
       "0       car park        PC      4.20     2.8    2.55    2.90   \n",
       "1   dream ticket        NC      1.32     1.7    1.80    1.90   \n",
       "2     case study         C      3.70     3.6    4.00    3.08   \n",
       "3  dutch courage        PC      1.00     0.8    0.80    0.70   \n",
       "4       cash cow        NC      1.56     0.8    0.20    0.55   \n",
       "\n",
       "                                            Synonyms             SynonymsS1  \\\n",
       "0  parking lot;parking lot;parking garage;vehicle...                 garage   \n",
       "1                  perfect combination;golden ticket                    NaN   \n",
       "2    example;specific example;medical trial;analysis  history;documentation   \n",
       "3              alcohol;liquid courage;liquid courage                    NaN   \n",
       "4  gold mine;money maker;moneymaker;moneymaker;st...                 income   \n",
       "\n",
       "           SynonymsS2          SynonymsS3  \n",
       "0                 NaN                 NaN  \n",
       "1               ideal  opportunity;chance  \n",
       "2                 NaN                 NaN  \n",
       "3  hitting the bottle                 NaN  \n",
       "4                 NaN                 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nctti_file = '../data/nctti/data_en.tsv'\n",
    "df_nctti = pd.read_csv(nctti_file, sep='\\t')\n",
    "df_nctti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c47e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f31a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find commond PIEs with lowest character-distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42888daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "magpie_pie_list = df_magpie_tokens['idiom'].values\n",
    "nctti_compounds = df_nctti['compound'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6751d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6677740863787376 keep a low profile , low profile\n",
      "1.0 pecking order , pecking order\n",
      "1.0 old hat , old hat\n",
      "1.0 close call , close call\n",
      "1.0 rock bottom , rock bottom\n",
      "1.0 basket case , basket case\n",
      "1.0 on cloud nine , cloud nine\n",
      "0.6677740863787376 get in on the ground floor , ground floor\n",
      "1.0 couch potato , couch potato\n",
      "1.0 shrinking violet , shrinking violet\n",
      "1.0 sitting duck , sitting duck\n",
      "1.0 an old flame , old flame\n",
      "1.0 banana republic , banana republic\n",
      "------------------------------\n",
      "Found 13 common idioms\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "magpie_nctti_common_pairs = []\n",
    "for mpie in magpie_pie_list:\n",
    "    for nc_comp in nctti_compounds:\n",
    "        mpie_words = mpie.split()\n",
    "        # Remove stop words\n",
    "        mpie_words = [mword for mword in mpie_words if mword not in en_stopwords]\n",
    "        nc_comp_words = [ncword for ncword in nc_comp.split() if ncword not in en_stopwords]\n",
    "        \n",
    "        #Find the edit distance\n",
    "        dist_score = nltk.edit_distance(mpie_words, nc_comp_words)\n",
    "        # Get Similarity as Ratio\n",
    "        sim_score = 1- (dist_score / (len(mpie_words)+0.01) )\n",
    "    \n",
    "        if sim_score > 0.55:\n",
    "            print(sim_score, mpie, ',', nc_comp)\n",
    "            cnt+=1\n",
    "            # Consider this as matching idiom\n",
    "            magpie_nctti_common_pairs.append( (mpie, nc_comp) )\n",
    "\n",
    "print('-'*30)\n",
    "print(f\"Found {cnt} common idioms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2401580b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep a low profile : ['low key', 'inconspicuous', 'inconspicuous', 'down low']\n",
      "pecking order : ['hierarchy', 'hierarchy', 'food chain']\n",
      "old hat : ['old fashioned', 'old fashioned', 'dated', 'old-fashioned', 'old-fashioned', 'out of date', 'old news', 'old news', 'uninteresting', 'sweet']\n",
      "close call : ['near miss', 'close shave', 'cliffhanger', 'close one']\n",
      "rock bottom : ['all time low', 'cheapest', 'lowest point', 'lowest point', 'absolute lowest']\n",
      "basket case : ['crazy', 'crazy', 'nervous wreck', 'defenseless', 'lost cause']\n",
      "on cloud nine : ['bliss', 'bliss', 'heaven', 'heaven', 'in heaven', 'top of the world', 'euphoria']\n",
      "get in on the ground floor : ['first floor', 'first floor', 'ground level', 'bottom floor', 'bottom floor', 'basement', 'first story', 'sweet']\n",
      "couch potato : ['lazy', 'lazy', 'lazy person', 'lazy person', 'inactive person', 'inactive person', 'sedentary individual']\n",
      "shrinking violet : ['shy person', 'shy person', 'shy', 'shy', 'wallflower', 'wuss', 'wuss', 'sweet']\n",
      "sitting duck : ['easy target', 'easy target', 'pushover', 'pushover', 'easy prey', 'helpless', 'exposed']\n",
      "an old flame : ['former lover', 'former lover', 'ex girlfriend', 'ex girlfriend', 'old love', 'past love', 'past love', 'old lover', 'sweet']\n",
      "banana republic : ['politically unstable', 'politically unstable', 'small nation', 'third world country', 'land']\n"
     ]
    }
   ],
   "source": [
    "# Obtain the list of all paraphrases (annotated synonyms) for these common idioms\n",
    "list_of_paraphrases = set()\n",
    "for mppie, nctti in magpie_nctti_common_pairs:\n",
    "    df_com_row = df_nctti[df_nctti['compound'] == nctti]\n",
    "    synonyms = df_com_row['Synonyms'].values[0].split(';')\n",
    "    print(mppie, ':', synonyms)\n",
    "    list_of_paraphrases.update(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b7ff496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute lowest',\n",
       " 'all time low',\n",
       " 'basement',\n",
       " 'bliss',\n",
       " 'bottom floor',\n",
       " 'cheapest',\n",
       " 'cliffhanger',\n",
       " 'close one',\n",
       " 'close shave',\n",
       " 'crazy',\n",
       " 'dated',\n",
       " 'defenseless',\n",
       " 'down low',\n",
       " 'easy prey',\n",
       " 'easy target',\n",
       " 'euphoria',\n",
       " 'ex girlfriend',\n",
       " 'exposed',\n",
       " 'first floor',\n",
       " 'first story',\n",
       " 'food chain',\n",
       " 'former lover',\n",
       " 'ground level',\n",
       " 'heaven',\n",
       " 'helpless',\n",
       " 'hierarchy',\n",
       " 'in heaven',\n",
       " 'inactive person',\n",
       " 'inconspicuous',\n",
       " 'land',\n",
       " 'lazy',\n",
       " 'lazy person',\n",
       " 'lost cause',\n",
       " 'low key',\n",
       " 'lowest point',\n",
       " 'near miss',\n",
       " 'nervous wreck',\n",
       " 'old fashioned',\n",
       " 'old love',\n",
       " 'old lover',\n",
       " 'old news',\n",
       " 'old-fashioned',\n",
       " 'out of date',\n",
       " 'past love',\n",
       " 'politically unstable',\n",
       " 'pushover',\n",
       " 'sedentary individual',\n",
       " 'shy',\n",
       " 'shy person',\n",
       " 'small nation',\n",
       " 'sweet',\n",
       " 'third world country',\n",
       " 'top of the world',\n",
       " 'uninteresting',\n",
       " 'wallflower',\n",
       " 'wuss'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af483263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB_VENV",
   "language": "python",
   "name": "lab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
